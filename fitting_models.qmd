---
title: "Fitting Models"
format: html
editor: visual
---

# Fitting Models

## Load in Data and Dependencies

```{r}
#| output: false
require(UsingR)
require(tgsify)
require(rms)
require(dplyr)
require(olsrr)
require(validate)
require(knitr)
require(kableExtra)
require(sjPlot)
require(ggplot2)
require(table1)
library(ggridges)
df<-read.csv('data/BRFSS_clean.csv')
drops <- c("SEQNO", "X", "DEAF", "BLIND", "DECIDE", "DIFFWALK", "DIFFDRES", "DIFFALON", "F")
df<-df[, !(names(df) %in% drops)]
#Train/Test Split
#make it reproducible
set.seed(1)

#use 80% of dataset as training set and 20% as test set
sample <- sample(c(TRUE, FALSE), nrow(df), replace=TRUE, prob=c(0.8,0.2))
train  <- df[sample, ]
test   <- df[!sample, ]
```

## Build Table 1

```{r}
df = df%>% mutate(DISABILITY = case_when(DISCORE>0 ~ 1,
                              DISCORE==0 ~0))
label(df$AGE)<-"Categorical Age"
label(df$M)<-"Male"
label(df$WHITE)<- "White"
label(df$BLACK)<- "Black"
label(df$ASIAN)<- "Asian"
label(df$AM_IN)<- "American Indian"
label(df$HISP)<- "Hispanic"
label(df$ANOTHER_RACE)<- "Another Race"
label(df$EMPL)<- "Employed"
label(df$COLLEGE)<- "College Graduate"
label(df$PARTNERED)<- "Partnered"
label(df$DISABILITY)<- "Disability Status"
label(df$MENTHLTH)<- "Number of Bad Mental Health Days in a Month"
suppressWarnings(table1(~ AGE+M+WHITE+BLACK+ASIAN+AM_IN+HISP+ANOTHER_RACE+EMPL+COLLEGE+PARTNERED+DISABILITY+MENTHLTH, data=df))
#Average age is around 55 years old 
drops <- c("DISABILITY")
df<-df[, !(names(df) %in% drops)]
```

## Histogram of Outcome

```{r}
hist(df$MENTHLTH, freq=FALSE, breaks=30, main='Histogram of Number of Bad Mental Health Days', xlab='Number of Bad Mental Health Days')
```

## Fit Basic Regression Model

```{r}
f1<- MENTHLTH ~ .
dd <- datadist(train)
options(datadist = "dd")
m1<- lm(f1, data = train, x=TRUE, y=TRUE)
predictions<- predict(m1, test)
predictions[predictions<0]<-0
predictions[predictions>30]<-30
rounded<- round(predictions, digits = 0)
acc <- rounded == test['MENTHLTH'] 
mean(acc)
error<-abs(predictions - test['MENTHLTH'])
mae<- (sum(error))/nrow(test)
mae
acc <- rounded == test['MENTHLTH'] |rounded == test['MENTHLTH']+1|rounded == test['MENTHLTH']-1
mean(acc)
```

### Cross Validation of Basic Regression

```{r}
#Randomly shuffle the data
df<-df[sample(nrow(df)),]

#Create 10 equally size folds
folds <- cut(seq(1,nrow(df)),breaks=5,labels=FALSE)
CV_MAE = rep(NA, 5)
CV_Acc = rep(NA, 5)
CV_Acc_spread = rep(NA, 5)
prediction_list <- list(0, 0, 0, 0, 0)

#Perform 10 fold cross validation
for(i in 1:5){
    #Segement your data by fold using the which() function 
    testIndexes <- which(folds==i,arr.ind=TRUE)
    testData <- df[testIndexes, ]
    trainData <- df[-testIndexes, ]
    #Use the test and train data partitions however you desire...
    m1<- lm(f1, data = train, x=TRUE, y=TRUE)
    predictions<- predict(m1, testData)
    predictions[predictions<0]<-0
    predictions[predictions>30]<-30
    rounded<- round(predictions, digits = 0)
    acc <- rounded == testData['MENTHLTH'] 
    CV_Acc[i] = mean(acc)
    error<-abs(predictions - test['MENTHLTH'])
    mae<- (sum(error))/nrow(test)
    CV_MAE[i] = mae
    acc <- rounded == testData['MENTHLTH'] |rounded == testData['MENTHLTH']+1|rounded == testData['MENTHLTH']-1
    CV_Acc_spread[i] = mean(acc)
    test2 = testData%>% mutate(predictions = rounded)
    prediction_list[[i]] = test2
}
predictions_df = bind_rows(prediction_list)
```

```{r}
mean(CV_MAE)
mean(CV_Acc)
mean(CV_Acc_spread)
```

```{r}
boxplot(
#predictions~MENTHLTH,
MENTHLTH~predictions,
data=predictions_df,
horizontal = TRUE,
xlab="Predicted Bad Mental Health Days",
ylab="Actual Bad Mental Health Days"
)
abline(a=0, b=1)
```

```{r}
df2 = predictions_df%>%
  group_by(predictions)%>% summarise(n=n(), score = mean(MENTHLTH))
ggplot(predictions_df, aes(x = MENTHLTH , y = predictions,fill= predictions, group=predictions)) +
  geom_density_ridges(bandwidth = .7) +
  theme_ridges()  +
  theme(legend.position = "none") + geom_abline(intercept=0, slope=1) + geom_point(aes(score, predictions), data = df2, inherit.aes = FALSE) +
coord_flip() + scale_y_continuous(name ="Predicted Number of Bad Days") + scale_x_continuous(name ="Actual Number of Bad Days") + ggtitle("Calibration in Linear Regression without Nonlinearity", ) + theme(axis.title.x = element_text(size=10, hjust = 0.5, vjust = 0.5), axis.title.y = element_text(size=10, hjust = 0.5, vjust = 0.5), plot.title = element_text(size=12, hjust = 0.5, vjust = 0.5), axis.text = element_text(size=10)) 
```

### Calibration of Basic Regression Model for Test Data

```{r}
test2 = test%>% mutate(predictions = rounded)
df2 = test2 %>%
  group_by(predictions)%>% summarise(n=n(), score = mean(MENTHLTH))
ggplot(df2, aes(x=predictions, y=score)) + geom_point()+ labs(x='Predicted Bad Mental Health Days', y='Actual Bad Mental Health Days')+geom_abline(intercept=0, slope=1)
```

```{r}
test2 = test%>% mutate(predictions = rounded)
calibration = subset(test2, select= c('predictions', 'MENTHLTH'))
confusion<- matrix(0, nrow=31, ncol=31)
calibration$predictions[calibration$predictions<0]<-0
calibration$predictions[calibration$predictions>30]<-30
count = 0
for(row in 1:nrow(calibration)){
  confusion[calibration[row, 1]+1, calibration[row, 2]+1] = confusion[calibration[row, 1]+1,calibration[row, 2]+1] + 1
}
accuracies = diag(confusion)/colSums(confusion)
barplot(accuracies, xlab = "Number of Bad Mental Health Days", ylab='Accuracy', names.arg = c(0:30), cex.names=.535)
```

### Calibration of Basic Regression Model for Training Data

```{r}
predictions<- predict(m1, data=train)
rounded<- round(predictions, digits = 0)
train2 = train%>% mutate(predictions = rounded)
df2 = train2 %>%
  group_by(predictions)%>% summarise(n=n(), score = mean(MENTHLTH))
ggplot(df2, aes(x=predictions, y=score)) + geom_point()+ labs(x='Predicted Bad Mental Health Days', y='Actual Bad Mental Health Days')+geom_abline(intercept=0, slope=1)
```

```{r}
f2 <- MENTHLTH ~ DIAB + HEALTHSCORE + rcs(PHYSHLTH,3) + HIGHBP+ HEARTATTACK + HEARTDISEASE + STROKE + ASTHMA + SKINCANCER + OTHERCANCER + LUNGISSUE + KIDNEYISSUE + ATHRITIS + PARTNERED + COLLEGE + OWNHOME + VET + EMPLOYED + CHILDREN + rcs(INCOMECAT, 3) + rcs(BMI,3) + rcs(AGEG5YR, 3) + SMOKE + ECIG + rcs(DRINKPERW, 3) + rcs(POTADAY, 3) + rcs(FRUIT_J_DAY, 3) + rcs(FRUITDAY, 3) + rcs(GRNVEGDAY,3) + rcs(OTHERVEGDAY, 3) + AFFORDOC + INSURED + EXERCISE + DISCORE + UNEMP + EMPL + RETIR + UNAB_WORK + M + WHITE + BLACK + ASIAN + AM_IND + HISP + ANOTHER_RACE
dd <- datadist(train)
options(datadist = "dd")
m2 <- lm(f2, data = train, x=TRUE, y=TRUE)
predictions<- predict(m2, test)
predictions[predictions<0]<-0
predictions[predictions>30]<-30
rounded<- round(predictions, digits = 0)
acc <- rounded == test['MENTHLTH'] 
mean(acc)
error<-abs(predictions - test['MENTHLTH'])
mae<- (sum(error))/nrow(test)
mae

acc <- rounded == test['MENTHLTH'] |rounded == test['MENTHLTH']+1|rounded == test['MENTHLTH']-1
mean(acc)
```

### Calibration of Complex Regression Model

```{r}
test2 = test%>% mutate(predictions = rounded)
df2 = test2 %>%
  group_by(predictions)%>% summarise(n=n(), score = mean(MENTHLTH))
ggplot(df2, aes(x=predictions, y=score)) + geom_point()+ labs(x='Predicted Bad Mental Health Days', y='Actual Bad Mental Health Days')+geom_abline(intercept=0, slope=1)
```

```{r}
test2 = test%>% mutate(predictions = rounded)
calibration = subset(test2, select= c('predictions', 'MENTHLTH'))
confusion<- matrix(0, nrow=31, ncol=31)
calibration$predictions[calibration$predictions<0]<-0
calibration$predictions[calibration$predictions>30]<-30
count = 0
for(row in 1:nrow(calibration)){
  confusion[calibration[row, 1]+1, calibration[row, 2]+1] = confusion[calibration[row, 1]+1,calibration[row, 2]+1] + 1
}
accuracies = diag(confusion)/colSums(confusion)
barplot(accuracies, xlab = "Number of Bad Mental Health Days", ylab='Accuracy', names.arg = c(0:30), cex.names=.535)
```

### Calibration of Complex Regression Model on Training Data

```{r}
predictions<- predict(m2, data=train)
rounded<- round(predictions, digits = 0)
train2 = train%>% mutate(predictions = rounded)
df2 = train2 %>%
  group_by(predictions)%>% summarise(n=n(), score = mean(MENTHLTH))
ggplot(df2, aes(x=predictions, y=score)) + geom_point()+ labs(x='Predicted Bad Mental Health Days', y='Actual Bad Mental Health Days')+geom_abline(intercept=0, slope=1)
```

```{r}
CV_MAE = rep(NA, 5)
CV_Acc = rep(NA, 5)
CV_Acc_spread = rep(NA, 5)
prediction_list <- list(0, 0, 0, 0, 0)

#Perform 10 fold cross validation
for(i in 1:5){
    #Segement your data by fold using the which() function 
    testIndexes <- which(folds==i,arr.ind=TRUE)
    testData <- df[testIndexes, ]
    trainData <- df[-testIndexes, ]
    #Use the test and train data partitions however you desire...
    m1<- lm(f2, data = train, x=TRUE, y=TRUE)
    predictions<- predict(m1, testData)
    predictions[predictions<0]<-0
    predictions[predictions>30]<-30
    rounded<- round(predictions, digits = 0)
    acc <- rounded == testData['MENTHLTH'] 
    CV_Acc[i] = mean(acc)
    error<-abs(predictions - test['MENTHLTH'])
    mae<- (sum(error))/nrow(test)
    CV_MAE[i] = mae
    acc <- rounded == testData['MENTHLTH'] |rounded == testData['MENTHLTH']+1|rounded == testData['MENTHLTH']-1
    CV_Acc_spread[i] = mean(acc)
    test2 = testData%>% mutate(predictions = rounded)
    prediction_list[[i]] = test2
}
predictions_df = bind_rows(prediction_list)

df2 = predictions_df%>%
  group_by(predictions)%>% summarise(n=n(), score = mean(MENTHLTH))
ggplot(predictions_df, aes(x = MENTHLTH , y = predictions,fill= predictions, group=predictions)) +
  geom_density_ridges(bandwidth = .7) +
  theme_ridges()  +
  theme(legend.position = "none") + geom_abline(intercept=0, slope=1) + geom_point(aes(score, predictions), data = df2, inherit.aes = FALSE) +
coord_flip() + scale_y_continuous(name ="Predicted Number of Bad Days") + scale_x_continuous(name ="Actual Number of Bad Days") + ggtitle("Calibration in Linear Regression with Nonlinearity", ) + theme(axis.title.x = element_text(size=10, hjust = 0.5, vjust = 0.5), axis.title.y = element_text(size=10, hjust = 0.5, vjust = 0.5), plot.title = element_text(size=12, hjust = 0.5, vjust = 0.5), axis.text = element_text(size=10)) 
```

```{r}
mean(CV_MAE)
mean(CV_Acc)
mean(CV_Acc_spread)
```

## Fit Ordinal Regression Model

```{r}
f2 <- MENTHLTH ~ DIAB + HEALTHSCORE + rcs(PHYSHLTH,3) + HIGHBP+ HEARTATTACK + HEARTDISEASE + STROKE + ASTHMA + SKINCANCER + OTHERCANCER + LUNGISSUE + KIDNEYISSUE + ATHRITIS + PARTNERED + COLLEGE + OWNHOME + VET + EMPLOYED + CHILDREN + rcs(INCOMECAT, 3) + rcs(BMI,3) + rcs(AGEG5YR, 3) + SMOKE + ECIG + rcs(DRINKPERW, 3) + rcs(POTADAY, 3) + rcs(FRUIT_J_DAY, 3) + rcs(FRUITDAY, 3) + rcs(GRNVEGDAY,3) + rcs(OTHERVEGDAY, 3) + AFFORDOC + INSURED + EXERCISE + DISCORE + UNEMP + EMPL + RETIR + UNAB_WORK + M + WHITE + BLACK + ASIAN + AM_IND + HISP + ANOTHER_RACE
dd <- datadist(train)
options(datadist = "dd")
m2 <- orm(f2, data = train, x=TRUE, y=TRUE)
predictions<- predict(m2, newdata=test)
predictions[predictions<0]<-0
predictions[predictions>30]<-30
rounded<- round(predictions, digits = 0)
acc <- rounded == test['MENTHLTH'] 
mean(acc)
error<-abs(predictions - test['MENTHLTH'])
mae<- (sum(error))/nrow(test)
mae

acc <- rounded == test['MENTHLTH'] |rounded == test['MENTHLTH']+1|rounded == test['MENTHLTH']-1
mean(acc)
```

```{r}
CV_MAE = rep(NA, 5)
CV_Acc = rep(NA, 5)
CV_Acc_spread = rep(NA, 5)
prediction_list <- list(0, 0, 0, 0, 0)

#Perform 10 fold cross validation
for(i in 1:5){
    #Segement your data by fold using the which() function 
    testIndexes <- which(folds==i,arr.ind=TRUE)
    testData <- df[testIndexes, ]
    trainData <- df[-testIndexes, ]
    #Use the test and train data partitions however you desire...
    m1<- orm(f2, data = train, x=TRUE, y=TRUE)
    predictions<- predict(m1, testData)
    predictions[predictions<0]<-0
    predictions[predictions>30]<-30
    rounded<- round(predictions, digits = 0)
    acc <- rounded == testData['MENTHLTH'] 
    CV_Acc[i] = mean(acc)
    error<-abs(predictions - test['MENTHLTH'])
    mae<- (sum(error))/nrow(test)
    CV_MAE[i] = mae
    acc <- rounded == testData['MENTHLTH'] |rounded == testData['MENTHLTH']+1|rounded == testData['MENTHLTH']-1
    CV_Acc_spread[i] = mean(acc)
    test2 = testData%>% mutate(predictions = rounded)
    prediction_list[[i]] = test2
}
predictions_df = bind_rows(prediction_list)

df2 = predictions_df%>%
  group_by(predictions)%>% summarise(n=n(), score = mean(MENTHLTH))
ggplot(predictions_df, aes(x = MENTHLTH , y = predictions,fill= predictions, group=predictions)) +
  geom_density_ridges(bandwidth = .7) +
  theme_ridges()  +
  theme(legend.position = "none") + geom_abline(intercept=0, slope=1) + geom_point(aes(score, predictions), data = df2, inherit.aes = FALSE) +
coord_flip() + scale_y_continuous(name ="Predicted Number of Bad Days") + scale_x_continuous(name ="Actual Number of Bad Days") + ggtitle("Calibration in Ordinal Regression with Nonlinearity", ) + theme(axis.title.x = element_text(size=10, hjust = 0.5, vjust = 0.5), axis.title.y = element_text(size=10, hjust = 0.5, vjust = 0.5), plot.title = element_text(size=12, hjust = 0.5, vjust = 0.5), axis.text = element_text(size=10))

mean(CV_MAE)
mean(CV_Acc)
mean(CV_Acc_spread)
```

```{r}
f2 <- MENTHLTH ~ DIAB + HEALTHSCORE + PHYSHLTH + HIGHBP+ HEARTATTACK + HEARTDISEASE + STROKE + ASTHMA + SKINCANCER + OTHERCANCER + LUNGISSUE + KIDNEYISSUE + ATHRITIS + PARTNERED + COLLEGE + OWNHOME + VET + EMPLOYED + CHILDREN + INCOMECAT + BMI + AGEG5YR + SMOKE + ECIG + DRINKPERW + POTADAY + FRUIT_J_DAY + FRUITDAY + GRNVEGDAY + OTHERVEGDAY + AFFORDOC + INSURED + EXERCISE + DISCORE + UNEMP + EMPL + RETIR + UNAB_WORK + M + WHITE + BLACK + ASIAN + AM_IND + HISP + ANOTHER_RACE

CV_MAE = rep(NA, 5)
CV_Acc = rep(NA, 5)
CV_Acc_spread = rep(NA, 5)
prediction_list <- list(0, 0, 0, 0, 0)

#Perform 10 fold cross validation
for(i in 1:5){
    #Segement your data by fold using the which() function 
    testIndexes <- which(folds==i,arr.ind=TRUE)
    testData <- df[testIndexes, ]
    trainData <- df[-testIndexes, ]
    #Use the test and train data partitions however you desire...
    m1<- orm(f2, data = train, x=TRUE, y=TRUE)
    predictions<- predict(m1, testData)
    predictions[predictions<0]<-0
    predictions[predictions>30]<-30
    rounded<- round(predictions, digits = 0)
    acc <- rounded == testData['MENTHLTH'] 
    CV_Acc[i] = mean(acc)
    error<-abs(predictions - test['MENTHLTH'])
    mae<- (sum(error))/nrow(test)
    CV_MAE[i] = mae
    acc <- rounded == testData['MENTHLTH'] |rounded == testData['MENTHLTH']+1|rounded == testData['MENTHLTH']-1
    CV_Acc_spread[i] = mean(acc)
    test2 = testData%>% mutate(predictions = rounded)
    prediction_list[[i]] = test2
}
predictions_df = bind_rows(prediction_list)

df2 = predictions_df%>%
  group_by(predictions)%>% summarise(n=n(), score = mean(MENTHLTH))
ggplot(predictions_df, aes(x = MENTHLTH , y = predictions,fill= predictions, group=predictions)) +
  geom_density_ridges(bandwidth = .7) +
  theme_ridges()  +
  theme(legend.position = "none") + geom_abline(intercept=0, slope=1) + geom_point(aes(score, predictions), data = df2, inherit.aes = FALSE) +
coord_flip() + scale_y_continuous(name ="Predicted Number of Bad Days") + scale_x_continuous(name ="Actual Number of Bad Days") + ggtitle("Calibration in Ordinal Regression without Nonlinearity", ) + theme(axis.title.x = element_text(size=10, hjust = 0.5, vjust = 0.5), axis.title.y = element_text(size=10, hjust = 0.5, vjust = 0.5), plot.title = element_text(size=12, hjust = 0.5, vjust = 0.5), axis.text = element_text(size=10)) 

mean(CV_MAE)
mean(CV_Acc)
mean(CV_Acc_spread)
```

### Calibration of Basic Ordinal Regression Model

```{r}
test2 = test%>% mutate(predictions = rounded)
df2 = test2 %>%
  group_by(predictions)%>% summarise(n=n(), score = mean(MENTHLTH))
ggplot(df2, aes(x=predictions, y=score)) + geom_point()+ labs(x='Predicted Bad Mental Health Days', y='Actual Bad Mental Health Days')+geom_abline(intercept=0, slope=1)+ xlim(-2,30)
```

```{r}
test2 = test%>% mutate(predictions = rounded)
calibration = subset(test2, select= c('predictions', 'MENTHLTH'))
confusion<- matrix(0, nrow=31, ncol=31)
calibration$predictions[calibration$predictions<0]<-0
calibration$predictions[calibration$predictions>30]<-30
count = 0
for(row in 1:nrow(calibration)){
  confusion[calibration[row, 1]+1, calibration[row, 2]+1] = confusion[calibration[row, 1]+1,calibration[row, 2]+1] + 1
}
accuracies = diag(confusion)/colSums(confusion)
barplot(accuracies, xlab = "Number of Bad Mental Health Days", ylab='Accuracy', names.arg = c(0:30), cex.names=.535)
```

### Calibration of Basic Ordinal Regression on Training Data

```{r}
predictions<- predict(m2, data=train)
rounded<- round(predictions, digits = 0)
train2 = train%>% mutate(predictions = rounded)
df2 = train2 %>%
  group_by(predictions)%>% summarise(n=n(), score = mean(MENTHLTH))
ggplot(df2, aes(x=predictions, y=score)) + geom_point()+ labs(x='Predicted Bad Mental Health Days', y='Actual Bad Mental Health Days')+geom_abline(intercept=0, slope=1)+ xlim(-2,30)
```

```{r}
f2 <- MENTHLTH ~ DIAB + HEALTHSCORE + rcs(PHYSHLTH,3) + HIGHBP+ HEARTATTACK + HEARTDISEASE + STROKE + ASTHMA + SKINCANCER + OTHERCANCER + LUNGISSUE + KIDNEYISSUE + ATHRITIS + PARTNERED + VET + EMPLOYED   + SMOKE + ECIG + rcs(DRINKPERW, 3) + rcs(POTADAY, 3) + rcs(FRUIT_J_DAY, 3) + rcs(FRUITDAY, 3) + rcs(GRNVEGDAY,3) + rcs(OTHERVEGDAY, 3) + AFFORDOC + INSURED + EXERCISE + DISCORE + UNEMP + EMPL + RETIR + UNAB_WORK + WHITE + BLACK + ASIAN + AM_IND + HISP + ANOTHER_RACE + CHILDREN * rcs(INCOMECAT, 3)*OWNHOME + COLLEGE + rcs(BMI,3) *rcs(AGEG5YR, 3)*M + rcs(INCOMECAT, 3)*M 

dd <- datadist(train)
options(datadist = "dd")
m2 <- orm(f2, data = train, x=TRUE, y=TRUE)
predictions<- predict(m2, newdata = test)
predictions[predictions<0]<-0
predictions[predictions>30]<-30
rounded<- round(predictions, digits = 0)
acc <- rounded == test['MENTHLTH'] 
mean(acc)
error<-abs(predictions - test['MENTHLTH'])
mae<- (sum(error))/nrow(test)
mae

acc <- rounded == test['MENTHLTH'] |rounded == test['MENTHLTH']+1|rounded == test['MENTHLTH']-1
mean(acc)
```

### Calibration of Complex Ordinal Regression Model on Test Data

```{r}
test2 = test%>% mutate(predictions = rounded)
df2 = test2 %>%
  group_by(predictions)%>% summarise(n=n(), score = mean(MENTHLTH))
ggplot(df2, aes(x=predictions, y=score)) + geom_point()+ labs(x='Predicted Bad Mental Health Days', y='Actual Bad Mental Health Days')+geom_abline(intercept=0, slope=1)+ xlim(-2,30)
```

```{r}
test2 = test%>% mutate(predictions = rounded)
calibration = subset(test2, select= c('predictions', 'MENTHLTH'))
confusion<- matrix(0, nrow=31, ncol=31)
calibration$predictions[calibration$predictions<0]<-0
calibration$predictions[calibration$predictions>30]<-30
count = 0
for(row in 1:nrow(calibration)){
  confusion[calibration[row, 1]+1, calibration[row, 2]+1] = confusion[calibration[row, 1]+1,calibration[row, 2]+1] + 1
}
accuracies = diag(confusion)/colSums(confusion)
barplot(accuracies, xlab = "Number of Bad Mental Health Days", ylab='Accuracy', names.arg = c(0:30), cex.names=.535)
```

### Calibration of Complex Ordinal Regression on Training Data

```{r}
predictions<- predict(m2, data=train)
rounded<- round(predictions, digits = 0)
train2 = train%>% mutate(predictions = rounded)
df2 = train2 %>%
  group_by(predictions)%>% summarise(n=n(), score = mean(MENTHLTH))
ggplot(df2, aes(x=predictions, y=score)) + geom_point()+ labs(x='Predicted Bad Mental Health Days', y='Actual Bad Mental Health Days')+geom_abline(intercept=0, slope=1)+ xlim(-2,30)
```

## Fit XGBoost

```{r}
# Load the required libraries
library(xgboost)
library(caret)

# Define the features and target variable
features <- setdiff(names(train), 'MENTHLTH')
target <- 'MENTHLTH'

# Define the XGBoost parameters
parameters <- list(
  objective = "reg:squarederror", # Use 'reg:squarederror' for a boosted tree
  eval_metric = "mae",
  eta = 0.1,
  max_depth = 5,
  min_child_weight = 1,
  subsample = 0.8,
  colsample_bytree = 0.8
)

# Train the XGBoost model
xgb_model <- xgboost(
  data = as.matrix(train[, features]),
  label = train[, target],
  params = parameters,
 # eval_metric = 'mae',
  nrounds = 100,
  early_stopping_rounds = 20
 #watchlist = list(train = as.matrix(train[, features]), 
               #   validation = as.matrix(validation_set[, features]))
)

# Make predictions on the testing dataset
test_pred <- predict(xgb_model, as.matrix(test[, features]))
rounded<- round(test_pred, digits = 0)
acc <- rounded == test['MENTHLTH'] #|rounded == test['MENTHLTH']+1|rounded == test['MENTHLTH']-1
mean(acc)
error<-abs(test_pred - test['MENTHLTH'])
mae<- (sum(error))/nrow(test)
mae


# Define the XGBoost parameters
parameters <- list(
  objective = "reg:squarederror", # Use 'reg:squarederror' for a boosted tree
  eval_metric = 'mae',
  eta = 0.1,
  max_depth = 5,
  min_child_weight = 1,
  subsample = 0.8,
  colsample_bytree = 0.8
)

cv<-xgb.cv(data = as.matrix(train[, features]),
  label = train[, target],
  params = parameters,
 # eval_metric = 'mae',
  nrounds = 100,
  early_stopping_rounds = 10,
 nthread=2, nfold=5)
```

```{r}
#Cross validation
learning_rates <-seq(0.001, .1, by= .005)
tree_num <- seq(20, 200, by=20)
cv_mins <- matrix(, nrow=length(learning_rates), ncol= length(tree_num))
for(i in 1:length(learning_rates)){
  for(k in 1:length(tree_num)){
    # Define the XGBoost parameters
    parameters <- list(
      objective = "reg:squarederror", # Use 'reg:squarederror' for a boosted tree
      eval_metric = "mae",
      eta = learning_rates[i],
      max_depth = 5,
      min_child_weight = 1,
      subsample = 0.8,
      colsample_bytree = 0.8
    )
    
    # Train the XGBoost model
    cv <- xgb.cv(
      data = as.matrix(train[, features]),
      label = train[, target],
      params = parameters,
     # eval_metric = 'mae',
      nrounds = tree_num[k],
     nthread=5,
     nfold = 5,
      early_stopping_rounds = 10,
     #watchlist = list(train = as.matrix(train[, features]), 
                   #   validation = as.matrix(validation_set[, features]))
    )
    cv_mins[i,k]<-min(cv$evaluation_log$test_mae_mean)
  }
}
```

## Documenting Min CV Accuracy

```{r}
#Checking accuracy of cross-validated best metrics for XGBoost
min(cv_mins)
which(cv_mins==min(cv_mins))    
mat_pos <- which(cv_mins == min(cv_mins),        # Set arr.ind = TRUE
                 arr.ind = TRUE)
mat_pos   
#Row 12 (learning rate), column 7 (max_iters)
learning_rate = .001 + 12*.005
max_iters = 20 + 20*7

test_pred <- predict(xgb_model, as.matrix(test[, features]))
rounded<- round(test_pred, digits = 0)
acc <- rounded == test['MENTHLTH'] #|rounded == test['MENTHLTH']+1|rounded == test['MENTHLTH']-1
mean(acc)
error<-abs(test_pred - test['MENTHLTH'])
mae<- (sum(error))/nrow(test)
mae
```

## Narrowing XGBoost Search Space

```{r}
#Cross validation
learning_rates_final <-seq(0.05, .07, by= .001)
tree_num_final <- seq(145, 175, by=1)
cv_mins_final <- matrix(, nrow=length(learning_rates_final), ncol= length(tree_num_final))
for(i in 1:length(learning_rates_final)){
  for(k in 1:length(tree_num_final)){
    # Define the XGBoost parameters
    parameters <- list(
      objective = "reg:squarederror", # Use 'reg:squarederror' for a boosted tree
      eval_metric = "mae",
      eta = learning_rates_final[i],
      max_depth = 5,
      min_child_weight = 1,
      subsample = 0.8,
      colsample_bytree = 0.8
    )
    
    # Train the XGBoost model
    cv <- xgb.cv(
      data = as.matrix(train[, features]),
      label = train[, target],
      params = parameters,
     # eval_metric = 'mae',
      nrounds = tree_num_final[k],
     nthread=5,
     nfold = 5,
      early_stopping_rounds = 10,
     #watchlist = list(train = as.matrix(train[, features]), 
                   #   validation = as.matrix(validation_set[, features]))
    )
    cv_mins_final[i,k]<-min(cv$evaluation_log$test_mae_mean)
  }
}
```

## Final Fit with Optimal XGBoost Terms

```{r}
min(cv_mins_final)
which(cv_mins_final==min(cv_mins_final))    
mat_pos <- which(cv_mins_final == min(cv_mins_final),        # Set arr.ind = TRUE
                 arr.ind = TRUE)
mat_pos   
#Row 14 (learning rate), column 28 (max_iters)
learning_rate = .005 + .001*13
max_iters = 45+27
```

```{r}
learning_rate = .005 + .001*13
max_iters = 45+27

# Define the features and target variable
features <- setdiff(names(train), 'MENTHLTH')
target <- 'MENTHLTH'

# Define the XGBoost parameters
parameters <- list(
  objective = "reg:squarederror", # Use 'reg:squarederror' for a boosted tree
  eval_metric = "mae",
  eta = learning_rate,
  max_depth = 5,
  min_child_weight = 1,
  subsample = 0.8,
  colsample_bytree = 0.8
)

# Train the XGBoost model
xgb_model <- xgboost(
  data = as.matrix(train[, features]),
  label = train[, target],
  params = parameters,
 # eval_metric = 'mae',
  nrounds = max_iters,
  early_stopping_rounds = 10
 #watchlist = list(train = as.matrix(train[, features]), 
               #   validation = as.matrix(validation_set[, features]))
)

# Make predictions on the testing dataset
test_pred <- predict(xgb_model, as.matrix(test[, features]))
test_pred[test_pred<0]<-0
test_pred[test_pred>30]<-30
rounded<- round(test_pred, digits = 0)
acc <- rounded == test['MENTHLTH'] #|rounded == test['MENTHLTH']+1|rounded == test['MENTHLTH']-1
mean(acc)
error<-abs(test_pred - test['MENTHLTH'])
mae<- (sum(error))/nrow(test)
mae

acc <- rounded == test['MENTHLTH'] |rounded == test['MENTHLTH']+1|rounded == test['MENTHLTH']-1
mean(acc)
```

```{r}
CV_MAE = rep(NA, 5)
CV_Acc = rep(NA, 5)
CV_Acc_spread = rep(NA, 5)
prediction_list <- list(0, 0, 0, 0, 0)

#Perform 10 fold cross validation
for(i in 1:5){
    #Segement your data by fold using the which() function 
    testIndexes <- which(folds==i,arr.ind=TRUE)
    testData <- df[testIndexes, ]
    trainData <- df[-testIndexes, ]
    #Use the test and train data partitions however you desire...
    xgb_model <- xgboost(
    data = as.matrix(trainData[, features]),
    label = trainData[, target],
    params = parameters,
   # eval_metric = 'mae',
    nrounds = max_iters,
    early_stopping_rounds = 10
   #watchlist = list(train = as.matrix(train[, features]), 
                 #   validation = as.matrix(validation_set[, features]))
  )
    predictions<- predict(xgb_model, as.matrix(testData[, features]))
    predictions[predictions<0]<-0
    predictions[predictions>30]<-30
    rounded<- round(predictions, digits = 0)
    acc <- rounded == testData['MENTHLTH'] 
    CV_Acc[i] = mean(acc)
    error<-abs(predictions - test['MENTHLTH'])
    mae<- (sum(error))/nrow(test)
    CV_MAE[i] = mae
    acc <- rounded == testData['MENTHLTH'] |rounded == testData['MENTHLTH']+1|rounded == testData['MENTHLTH']-1
    CV_Acc_spread[i] = mean(acc)
    test2 = testData%>% mutate(predictions = rounded)
    prediction_list[[i]] = test2
}
predictions_df = bind_rows(prediction_list)

df2 = predictions_df%>%
  group_by(predictions)%>% summarise(n=n(), score = mean(MENTHLTH))
ggplot(predictions_df, aes(x = MENTHLTH , y = predictions,fill= predictions, group=predictions)) +
  geom_density_ridges(bandwidth = .7) +
  theme_ridges()  +
  theme(legend.position = "none") + geom_abline(intercept=0, slope=1) + geom_point(aes(score, predictions), data = df2, inherit.aes = FALSE) +
coord_flip() + scale_y_continuous(name ="Predicted Number of Bad Days") + scale_x_continuous(name ="Actual Number of Bad Days") + ggtitle("Calibration in XGBoost", ) + theme(axis.title.x = element_text(size=10, hjust = 0.5, vjust = 0.5), axis.title.y = element_text(size=10, hjust = 0.5, vjust = 0.5), plot.title = element_text(size=12, hjust = 0.5, vjust = 0.5), axis.text = element_text(size=10)) 

mean(CV_MAE)
mean(CV_Acc)
mean(CV_Acc_spread)
```

### Calibration of XGBoost on Testing Data

```{r}
test2 = test%>% mutate(predictions = rounded)
df2 = test2 %>%
  group_by(predictions)%>% summarise(n=n(), score = mean(MENTHLTH))
ggplot(df2, aes(x=predictions, y=score)) + geom_point()+ labs(x='Predicted Bad Mental Health Days', y='Actual Bad Mental Health Days')+geom_abline(intercept=0, slope=1)+ xlim(0,30)
```

```{r}
test2 = test%>% mutate(predictions = rounded)
calibration = subset(test2, select= c('predictions', 'MENTHLTH'))
confusion<- matrix(0, nrow=31, ncol=31)
calibration$predictions[calibration$predictions<0]<-0
calibration$predictions[calibration$predictions>30]<-30
count = 0
for(row in 1:nrow(calibration)){
  confusion[calibration[row, 1]+1, calibration[row, 2]+1] = confusion[calibration[row, 1]+1,calibration[row, 2]+1] + 1
}
accuracies = diag(confusion)/colSums(confusion)
barplot(accuracies, xlab = "Number of Bad Mental Health Days", ylab='Accuracy', names.arg = c(0:30), cex.names=.535)
```

### Calibration of XGBoost on Training Data

```{r}
test_pred <- predict(xgb_model, newdata = as.matrix(train[, features]))
rounded<- round(test_pred, digits = 0)
train2 = train%>% mutate(predictions = rounded)
df2 = train2 %>%
  group_by(predictions)%>% summarise(n=n(), score = mean(MENTHLTH))
ggplot(df2, aes(x=predictions, y=score)) + geom_point()+ labs(x='Predicted Bad Mental Health Days', y='Actual Bad Mental Health Days')+geom_abline(intercept=0, slope=1)+ xlim(-2,30)
```

## Fit SVM

```{r}
# Load required library
library(e1071)

svm_subset<-train[1:100000,]
# Build the SVM model
svm_model <- svm(MENTHLTH ~ ., data = train, kernel = "poly", degree = 3)

# Make predictions on the testing data
predictions<- predict(svm_model, newdata = test)

# Calculate the accuracy of the model
rounded<- round(predictions, digits = 0)
acc <- rounded == test['MENTHLTH'] 
mean(acc)
error<-abs(predictions - test['MENTHLTH'])
mae<- (sum(error))/nrow(test)
mae

```

```{r}
#Tune SVM Model
#tune model
tune_out <- 
    tune.svm(x = train[, features], y = train[, target], 
             type = "nu-regression", 
             kernel = "polynomial", degree = 3, cost = 10^(0:3), 
             gamma = c(.1, 1, 10), coef0 = c(0.1, 1, 10))

#list optimal values
tune_out$best.parameters$degree
tune_out$best.parameters$gamma
tune_out$best.parameters$coef0
```

Other models if time- decision trees, KNN

```{r}
predictions_df<-read.csv('data/rf_predictions')
df2 = predictions_df%>%
  group_by(predictions)%>% summarise(n=n(), score = mean(actual))
ggplot(predictions_df, aes(x = actual , y = predictions,fill= predictions, group=predictions)) +
  geom_density_ridges(bandwidth = .7) +
  theme_ridges()  +
  theme(legend.position = "none") + geom_abline(intercept=0, slope=1) + geom_point(aes(score, predictions), data = df2, inherit.aes = FALSE) +
coord_flip() + scale_y_continuous(name ="Predicted Number of Bad Days") + scale_x_continuous(name ="Actual Number of Bad Days") + ggtitle("Calibration in Random Forest", ) + theme(axis.title.x = element_text(size=10, hjust = 0.5, vjust = 0.5), axis.title.y = element_text(size=10, hjust = 0.5, vjust = 0.5), plot.title = element_text(size=12, hjust = 0.5, vjust = 0.5), axis.text = element_text(size=10)) 

```
